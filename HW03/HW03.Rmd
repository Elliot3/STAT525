---
title: 'Assignment #3'
author: "Elliot Smith"
date: "9/9/2018"
output: pdf_document
---

# Problem 1

Sampling Distribution: $y_1, ..., y_n|\theta \overset{\text{iid}}{\sim} N(\theta, \sigma^2_y)$
\newline
Prior Distribution: $\theta \sim N(\mu_\theta, \sigma^2_\theta)$
\newline
Posterior Distribution: $\theta|y \sim N(Q^{-1}_\theta{\ell_\theta}, Q^{-1}_\theta)$
\newline
\newline
Posterior Distribution:
\newline
\[
\begin{aligned}
p(\theta|y) & \propto p(y|\theta)p(\theta) \\
& = \Bigg[\frac{1}{\sqrt{2\pi\sigma^2_y}}\Bigg]^n{exp\Bigg(-\frac{1}{2\sigma^2_y}\sum_{i=1}^n(y_i - \theta)^2\Bigg)}
\times \frac{1}{\sqrt{2\pi\sigma^2_\theta}}{exp\Bigg(-\frac{1}{2\sigma^2_\theta}(\theta - \mu_\theta)^2\Bigg)} \\
& \propto {exp\Bigg(-\frac{1}{2\sigma^2_\theta}(\theta - \mu_\theta)^2\Bigg)}
\times {exp\Bigg(-\frac{1}{2\sigma^2_y}\sum_{i=1}^n(y_i - \theta)^2\Bigg)} \\
& = exp\Bigg(-\frac{\theta^2 - 2\theta{\mu_\theta} + \mu_\theta^2}{2\sigma^2_\theta}\Bigg)
\times exp\Bigg(-\frac{\sum_{i=1}^n (y_i^2 - 2\theta{y_i} + \theta^2)}{2\sigma^2_y}\Bigg) \\
& = exp\Bigg(\frac{-\theta^2 + 2\theta{\mu_\theta} - \mu_\theta^2}{2\sigma^2_\theta}
- \frac{\sum_{i=1}^n (y_i^2 - 2\theta{y_i} + \theta^2)}{2\sigma^2_y}\Bigg) \\
& = exp\Bigg(\frac{\sigma^2_y[-\theta^2 + 2\theta{\mu_\theta} - \mu_\theta^2] - \sigma^2_\theta[\sum_{i=1}^n (y_i^2 - 2\theta{y_i} + \theta^2)]}
{2\sigma^2_\theta{\sigma^2_y}}\Bigg) \\
& = exp\Bigg(\frac{-\theta^2(\sigma^2_y + n \sigma^2_\theta) + 2\theta(\mu_\theta\sigma^2_y + \sigma^2_\theta{y_1} + ... + \sigma^2_\theta{y_n})
- (\mu_\theta^2{\sigma^2_y + \sigma^2_\theta{y_1^2}} + ... + \sigma^2_\theta{y_n^2})}{2\sigma^2_\theta{\sigma^2_y}}\Bigg) \\
& = exp\Bigg(\frac{-\theta^2 + 2\theta\frac{\mu_\theta{\sigma^2_y} + \sum_{i=1}^n \sigma^2_\theta{y_i}}{\sigma^2_y + n\sigma^2_\theta} - 
\bigg(\frac{\mu_\theta\sigma^2_y + \sum_{i=1}^n \sigma^2_\theta{y_i}}{\sigma^2_y + n\sigma^2_\theta}\bigg)}{2\frac{\sigma^2_\theta{\sigma^2_y}}{\sigma^2_y + n\sigma^2_\theta}}\Bigg)
\times exp\Bigg(-\frac{\mu_\theta^2\sigma_y^2 + \sum_{i=1}^n \sigma^2_\theta{y_i^2}}{2\sigma^2_\theta\sigma^2_y}\Bigg) \\
& = exp\Bigg(-\frac{\bigg(\theta - \frac{\mu_\theta\sigma^2_y + \sum_{i=1}^n \sigma^2_\theta{y_i}}{\sigma^2_y + n\sigma^2_\theta}\bigg)^2}
{2\frac{\sigma^2_\theta\sigma^2_y}{\sigma^2_y + n\sigma^2_\theta}}\Bigg) \\
\end{aligned}
\]

\newpage

From this result, we can see the following result:
\newline
\[
\begin{aligned}
\theta|y & \sim N\bigg(\frac{\mu_\theta\sigma^2_y + \sum_{i=1}^n \sigma_\theta^2{y_i}}{\sigma^2_y + n\sigma^2_\theta},
\frac{\sigma^2_y\sigma^2_\theta}{\sigma^2_y + n\sigma^2_\theta}\bigg) \\
& \sim N\bigg(\frac{\mu_\theta\sigma^{-2}_\theta + {\sigma_y^{-2}}\sum_{i=1}^n {y_i}}{\sigma^{-2}_\theta + n\sigma^{-2}_y},
\frac{1}{\sigma^{-2}_\theta + n\sigma^{-2}_y}\bigg) \\
& \sim N(Q^{-1}_\theta{\ell_\theta}, Q^{-1}_\theta)
\end{aligned}
\]
\newline
Where the following holds:
\newline
\newline
$Q_\theta = n\sigma^{-2}_y + \sigma^{-2}_\theta$
\newline
$\ell_\theta = \sigma^{-2}_y \sum_{i=1}^n y_i + \sigma^{-2}_\theta{\mu_\theta}$

# Problem 2

## Part i

Posterior Distribution:
\newline
\[
\begin{aligned}
p(\theta|y, \tau_y) & = \frac{1}{\sqrt{2\pi{\sigma^2_y}}}exp\bigg[-\frac{1}{2\sigma^2_y}\sum_{i=1}^n (y_i - \theta{x_i})^2\bigg] \\
& \propto exp\bigg[-\frac{1}{2\sigma^2_y}\sum_{i=1}^n (y_i - \theta{x_i})^2\bigg] \\
& = exp\Bigg[-\frac{1}{2}\bigg(\frac{1}{\sigma^2_y}\sum_{i=1}^n (y_i^2 -2\theta{x_i}{y_i} + \theta^2{x_i^2}\bigg)\Bigg] \\
& = exp\Bigg[-\frac{1}{2}\bigg(\frac{1}{\sigma^2_y}\bigg[\sum_{i=1}^n y_i^2 - \sum_{n=1}^n 2\theta{x_i}{y_i} + \sum_{i=1}^n \theta^2{x_i^2}\bigg]\bigg)\Bigg] \\
& = exp\Bigg[-\frac{1}{2}\bigg(\frac{1}{\sigma^2_y}\bigg[\sum_{i=1}^n y_i^2 - {2\theta}\sum_{n=1}^n {x_i}{y_i} + {\theta^2} \sum_{i=1}^n {x_i^2}\bigg]\bigg)\Bigg] \\
& = exp\Bigg[-\frac{1}{2}\bigg(\sigma^{-2}_y\sum_{i=1}^n y_i^2 - {2\theta}\sigma^{-2}_y\sum_{n=1}^n {x_i}{y_i} + {\theta^2}\sigma^{-2}_y \sum_{i=1}^n {x_i^2}\bigg)\Bigg] \\
& \propto exp\Bigg[-\frac{1}{2}\bigg({\theta^2}\sigma^{-2}_y \sum_{i=1}^n {x_i^2} - {2\theta}\sigma^{-2}_y\sum_{n=1}^n {x_i}{y_i}\bigg)\Bigg] \\
\end{aligned}
\]
\newline
Now, given the formula: $p(\theta|y) \propto exp\bigg[-\frac{1}{2}\bigg(Q_\theta{\theta^2} - 2\ell_\theta{\theta}\bigg)\bigg]$
\newline
\newline
We get the results that:
\newline
\newline
$Q_\theta = \sigma^{-2}_y \sum_{i=1}^n {x_i^2}$
\newline
$\ell_\theta = \sigma^{-2}_y\sum_{n=1}^n {x_i}{y_i}$
\newline
\[
\begin{aligned}
p(\theta|y, \tau_y) & \sim N(Q_\theta^{-1}\ell_\theta, Q_\theta^{-1}) \\
& \sim N\bigg(\big(\sigma^{-2}_y \sum_{i=1}^n {x_i^2}\big)^{-1} \times \sigma^{-2}_y\sum_{n=1}^n {x_i}{y_i}, \big(\sigma^{-2}_y \sum_{i=1}^n {x_i^2}\big)^{-1} \bigg)
\end{aligned}
\]

## Part ii

Prior Distribution: $\tau_y \sim Gamma(\alpha, \beta)$
\newline
Normal Likelihood: The derivation from Part i
\newline
Posterior Distribution: $[\tau_y|y] \sim Gamma(\alpha + \frac{n -1}{2}, \beta + \frac{(n - 1)s^2}{2}$
\newline
\newline
Our Goal:

1. Remove terms that don't depend on $\theta$
2. Integrate with respect to $\theta$ (integral is proportional to Normal pdf)
3. See that result is proportional to Gamma pdf

\[
\begin{aligned}
p(\tau_t|y) & = \int_\theta p(\tau_y, \theta|y)p(\theta)d{\theta} \\
& = \int_\theta p(\tau_y)p(y|\theta, \tau_y)d{\theta} \\
& = \int_\theta \theta^{\alpha-1}e^{-\beta{\theta}} \times
exp\Bigg[-\frac{1}{2}\bigg(\theta^2{\sigma_y^{-2}}\sum_{i=1}^n x_i^2 - 2\theta{\sigma_y^{-2}}\sum_{i=1}^n {x_i}{y_i}\bigg)\Bigg]d\theta \\
& = \int_\theta \theta^{\alpha-1} \times
exp\Bigg[-\frac{1}{2}\bigg(\theta^2{\sigma_y^{-2}}\sum_{i=1}^n x_i^2 - 2\theta{\sigma_y^{-2}}\sum_{i=1}^n {x_i}{y_i}\bigg) - {\beta{\theta}}\Bigg]d\theta \\
\end{aligned}
\]
\newline
I could not get passed this point as I was unable to get this quantity into the form required for it to represent a Gamma distribution. As you can see, I understand the general concept, but I was unable to get past this point in this problem.

## Part iii

Below is a sample of 10 draws from my sample of $10^4$ draws of the posterior distribution, $[\theta, \tau_y|y]$. Please refer to my code (in the Code Appendix section) for the precise sampling strategy.

```{r, echo = FALSE}

## Set options

options(scipen = 999)

## Load in the necessary packages

library(gamair)
library(coda)

## Load in the data

data("hubble")

x <- hubble$x
y <- hubble$y

## Setup the parameters

alpha <- 0.01
beta <- 0.01
n <- 24
theta_hat <- sum(x * y) / sum(x^2)
s_squared <- (1 / (n - 1)) * sum(y - (x * theta_hat))^2

## Make 10,000 draws from [tau_y|y], tau^s

draws_1 <- rgamma(n = 10000, shape = alpha + ((n - 1) / 2), rate = beta + (n - 1) * (s_squared / 2))

## Make 10,000 draws from [theta|y, tau_y = t^s]

var_y <- 1 / draws_1

draws_2 <- rnorm(n = 10000,
                 mean = ((1/var_y) * sum(x^2))^(-1) * (1/var_y) * sum(x * y),
                 sd = sqrt(((1/var_y) * sum(x^2))^(-1))
                 )

## Print out a sample of the draws

draw_samp <- sample(x = draws_2, size = 10)

cat("Sample Draw:\n\n", draw_samp)

```

## Part iv

Below is the 95% HPD interval for the age of the universe in years after the designated data transformations. Again, please refer to my code in the Code Appendix section for details on the algorithm used.

```{r, echo = FALSE}

## Construct the HPD interval

post_hub <- 1/draws_2*3.09e19/(60^2*24*365)

hpd_int <- as.vector(HPDinterval(as.mcmc(post_hub), prob = 0.95))

cat("HPD Interval: ", "(", hpd_int[1], ",", hpd_int[2], ")")

```

\newpage

# Problem 3

Sampling Distribution: $p(y|\theta) = \frac{\theta^ye^-\theta}{y!}$
\newline
Domain: $\theta > 0$
\newline
\newline
\[
\begin{aligned}
p(y|\theta) & = \prod_{i=1}^{n}\frac{\theta^{y_i}e^-{\theta}}{{y_i}!} \\
& = \theta^{{\sum_{i=1}^n}{y_i}}e^{-n\theta} \times \prod_{i=1}^n \frac{1}{{y_i}!} \\
log[p(y|\theta)] & = log\bigg[\theta^{{\sum_{i=1}^n}{y_i}}e^{-n\theta} \times \prod_{i=1}^n \frac{1}{{y_i}!}\bigg] \\
& = \bigg[{\sum_{i=1}^n}{y_i}\bigg]log(\theta) - n\theta - log\bigg[\sum_{i=1}^n{y_i}!\bigg] \\
\frac{d}{d\theta}log[p(y|\theta)] & = \frac{d}{d\theta}\Bigg[\bigg[{\sum_{i=1}^n}{y_i}\bigg]log(\theta)\Bigg]  - \frac{d}{d\theta}({n\theta}) + 0\\
& = \bigg[\sum_{i=1}^n{y_i}\bigg]{\frac{1}{\theta}} - n \\
\frac{d^2}{d\theta^2}log[p(y|\theta)] & = \bigg[\sum_{i=1}^n\frac{d}{d\theta} \theta^{-1}\bigg] + 0 \\
& = \frac{-\sum_{i=1}^n{y_i}}{\theta^2} \\
E\bigg[\frac{d^2log[p(y|\theta)]}{d\theta^2}\bigg|\theta\bigg] & = \frac{-n\theta}{\theta^2} \\
& = \frac{-n}{\theta} \\
\sqrt{-E\bigg[\frac{d^2log[p(y|\theta)]}{d\theta^2}\bigg|\theta\bigg]} & = \sqrt{\frac{n}{\theta}} \\
& \propto \theta^{-\frac{1}{2}} \\
& \sim Gamma\bigg(\alpha = \frac{1}{2}, \beta = 0\bigg)
\end{aligned}
\]

\newpage

# Code Appendix

```{r, eval = FALSE}

########## Problem 2 ##########





## Set options

options(scipen = 999)

## Load in the necessary packages

library(gamair)
library(coda)

## Load in the data

data("hubble")

x <- hubble$x
y <- hubble$y

## Setup the parameters

alpha <- 0.01
beta <- 0.01
n <- 24
theta_hat <- sum(x * y) / sum(x^2)
s_squared <- (1 / (n - 1)) * sum(y - (x * theta_hat))^2



##### Part iii #####



## Make 10,000 draws from [tau_y|y], tau^s

draws_1 <- rgamma(n = 10000, shape = alpha + ((n - 1) / 2),
                  rate = beta + (n - 1) * (s_squared / 2))

## Make 10,000 draws from [theta|y, tau_y = t^s]

var_y <- 1 / draws_1

draws_2 <- rnorm(n = 10000,
                 mean = ((1/var_y) * sum(x^2))^(-1) * (1/var_y) * sum(x * y),
                 sd = sqrt(((1/var_y) * sum(x^2))^(-1))
                 )

## Print out a sample of the draws

draw_samp <- sample(x = draws_2, size = 10)

cat("Sample Draw:\n\n", draw_samp)



##### Part iv #####



## Construct the HPD interval

post_hub <- 1/draws_2*3.09e19/(60^2*24*365)

hpd_int <- as.vector(HPDinterval(as.mcmc(post_hub), prob = 0.95))

cat("HPD Interval: ", "(", hpd_int[1], ",", hpd_int[2], ")")

```



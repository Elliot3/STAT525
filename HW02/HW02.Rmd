---
title: 'Assignment #2'
author: "Elliot Smith"
date: "8/30/2018"
output: pdf_document
---

# Problem 1

## Part a

Here our goal will be to minimize $a$ to show that $a = E[\theta|y]$ is the unique Bayes estimate of $\theta$:

\[
\begin{aligned}
\frac{d}{da}E[L(a|y)] & = \frac{d}{da}{\int}L(\theta, a)p(\theta|y)d\theta \\
& = \frac{d}{da}{\int}(\theta - a)^2p(\theta|y)d\theta \\
& = -2{\int}(\theta - a)p(\theta|y)d\theta \\
& = -2\bigg[{\int}{\theta}p(\theta|y)d\theta - a{\int}p(\theta|y)d\theta\bigg] \\
& = -2\big[E[\theta|y] - a\big] \\
\end{aligned}
\]

$-2\big[E[\theta|y] - a\big] = 0$ when $a = E[\theta|y]$
\newline
\newline
To prove that it is a unique minimizing statistic, we must look at the second derivative:
\newline
\newline
$\frac{d}{da}(-2\big[E[\theta|y] - a\big]) = 2$
\newline
\newline
As $2 > 0$, this shows that it is a unique minimzing statistic.

## Part b

Here our goal will be to show that for any median value of $a$, the derivative of $L(\theta, a)$ will evaluate to $0$.

\[
\begin{aligned}
\frac{d}{da}\big[E[L(a|y)]\big] & = \frac{d}{da}\bigg[{\int}_{-\infty}^a (a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty (\theta - a)p(\theta|y)d\theta\bigg] \\
& = {\int}_{-\infty}^a \frac{d}{da}(a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty \frac{d}{da}(\theta - a)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a p(\theta|y)d\theta + {\int}_{a}^\infty(-1)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a p(\theta|y)d\theta - {\int}_{a}^\infty p(\theta|y)d\theta \\
& = \frac{1}{2} - \frac{1}{2} \\
& = 0
\end{aligned}
\]

As a result, it has been shown that any posterior median of $\theta$ is a Bayes estimate of $\theta$.

## Part c

Here our goal will be to show that for any value of $a$, the derivative of $L(\theta, a)$ will evaluate to $0$ where $k_0$ and $k_1$ are nonnegative numbers.

\[
\begin{aligned}
\frac{d}{da}\big[E[L(a|y)]\big] & = \frac{d}{da}\bigg[{\int}_{-\infty}^a k_1(a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty k_0(\theta - a)p(\theta|y)d\theta\bigg] \\
& = {\int}_{-\infty}^a \frac{d}{da}k_1(a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty \frac{d}{da}k_0(\theta - a)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a {k_1}p(\theta|y)d\theta + {\int}_{a}^\infty(-k_0)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a {k_1}p(\theta|y)d\theta - {\int}_{a}^\infty {k_0}p(\theta|y)d\theta \\
& = k_1 {\int}_{-\infty}^a p(\theta|y)d\theta - k_0 {\int}_{a}^\infty p(\theta|y)d\theta \\
\end{aligned}
\]

Noting that: $k_0 \int_a^\infty p(\theta|y)d\theta = k_0 - k_0{\int_{-\infty}^a} p(\theta|y)d\theta$

\[
\begin{aligned}
k_1 {\int}_{-\infty}^a p(\theta|y)d\theta - k_0 {\int}_{a}^\infty p(\theta|y)d\theta & = k_1{\int_{-\infty}^a}p(\theta|y)d\theta - \bigg[k_0 - k_0{\int_{-\infty}^a} p(\theta|y)d\theta{\bigg]} \\
& = k_1{\int_{-\infty}^a}p(\theta|y)d\theta + k_0{\int_{-\infty}^a} p(\theta|y)d\theta - k_0 \\
& = (k_1 + k_0){\int_{-\infty}^a}p(\theta|y)d\theta - k_0 \\
\end{aligned}
\]

Now setting ${\int_{-\infty}^a}p(\theta|y)d\theta = \frac{k_0}{k_0 + k_1}$ we get our result that any quantile is a Bayes estimate of $\theta$.
\newline
\newline
Taking the second derivative we again get a positive number, thus again indicating that it is a minimizing statistic.

# Problem 2

n = 20
\newline
Sampling Distribution: $y|\theta \sim Binomial(n = 20, \theta)$
\newline
Prior Distribution: $\theta \sim Beta(\alpha = 2, \beta = 20)$
\newline
Posterior Distribution:
\newline
\[
\begin{aligned}
p(\theta|y) & = \binom{n}{y}\theta^y(1 - \theta)^{n - y} \times \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha - 1}(1 - \theta)^{\beta - 1} \\
& = \binom{n}{y}\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{y + \alpha - 1}(1 - \theta)^{n - y + \beta - 1} \\
& \propto Beta(y + \alpha, (n - y) + \beta) \\
& = Beta(y + 2, (20 - y) + 20)
\end{aligned}
\]

```{r, echo = FALSE}

### Load in the necessary packages

library(ggplot2)
library(coda)



##### Problem 2 #####



## Set the parameter values

y <- 0
n <- 20
alpha <- 2
beta <- 20

## Set the theta values

theta <- seq(from = 0, to = 1, length.out = 1000)

```

## Part i

$y = 0$
\newline

```{r, echo = FALSE, fig.height = 3}

### Part i ###



## Plot the posterior distribution

post_beta_dens <- dbeta(x = theta, shape1 = y + alpha, shape2 = (n - y) + beta)

ggplot() +
    geom_line(aes(x = theta, y = post_beta_dens), col = "blue") +
    geom_line(aes(x = theta, y = dbeta(x = theta, shape1 = alpha, shape2 = beta)), col = "green") +
    geom_vline(aes(xintercept = (y / n)), col = "red") +
    labs(x = "Theta", y = "Density", title = "Beta Density",
         subtitle = "Blue - Posterior Distribution   /   Green - Prior Distribution   /   Red - MLE")

```

## Part ii

```{r, echo = FALSE}

### Part ii ###



## Draw a sample from my posterior distribution

post_beta_rand <- rbeta(n = 10000, shape1 = y + alpha, shape2 = (n - y) + beta)

## Compute the HPD interval

bayes_int <- as.vector(HPDinterval(as.mcmc(post_beta_rand), prob = 0.95)[1, 1:2])

## Calculate the MLE

y_hat <- (y / n)

## Compute the frequentist interval

freq_int <- c((y_hat) - (1.96 * (sqrt(y_hat * (1 - y_hat)) / 2)),
              (y_hat) + (1.96 * (sqrt(y_hat * (1 - y_hat)) / 2)))

## Output the results

cat("HPD Interval: ", "(", bayes_int[1], ",", bayes_int[2], ")")
cat("Frequentist Interval: ", "(", freq_int[1], ",", freq_int[2], ")")

```

## Part iii

```{r, echo = FALSE}

### Part iii ###



## Compute the log odds of our posterior beta distrbution

odds_samp <- log(post_beta_rand / (1 - post_beta_rand))

## Compute the HPS interval

bayes_int_odds <- as.vector(HPDinterval(as.mcmc(odds_samp), prob = 0.95)[1, 1:2])

## Output the result

cat("HPD Interval: ", "(", bayes_int_odds[1], ",", bayes_int_odds[2], ")")

```














---
title: 'Assignment #2'
author: "Elliot Smith"
date: "8/30/2018"
output: pdf_document
---

# Problem 1

## Part a

Here our goal will be to minimize $a$ to show that $a = E[\theta|y]$ is the unique Bayes estimate of $\theta$:

\[
\begin{aligned}
\frac{d}{da}E[L(a|y)] & = \frac{d}{da}{\int}L(\theta, a)p(\theta|y)d\theta \\
& = \frac{d}{da}{\int}(\theta - a)^2p(\theta|y)d\theta \\
& = -2{\int}(\theta - a)p(\theta|y)d\theta \\
& = -2\bigg[{\int}{\theta}p(\theta|y)d\theta - a{\int}p(\theta|y)d\theta\bigg] \\
& = -2\big[E[\theta|y] - a\big] \\
\end{aligned}
\]

$-2\big[E[\theta|y] - a\big] = 0$ when $a = E[\theta|y]$
\newline
\newline
To prove that it is a unique minimizing statistic, we must look at the second derivative:
\newline
\newline
$\frac{d}{da}(-2\big[E[\theta|y] - a\big]) = 2$
\newline
\newline
As $2 > 0$, this shows that it is a unique minimzing statistic.

## Part b

Here our goal will be to show that for any median value of $a$, the derivative of $L(\theta, a)$ will evaluate to $0$.

\[
\begin{aligned}
\frac{d}{da}\big[E[L(a|y)]\big] & = \frac{d}{da}\bigg[{\int}_{-\infty}^a (a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty (\theta - a)p(\theta|y)d\theta\bigg] \\
& = {\int}_{-\infty}^a \frac{d}{da}(a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty \frac{d}{da}(\theta - a)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a p(\theta|y)d\theta + {\int}_{a}^\infty(-1)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a p(\theta|y)d\theta - {\int}_{a}^\infty p(\theta|y)d\theta \\
& = \frac{1}{2} - \frac{1}{2} \\
& = 0
\end{aligned}
\]

As a result, it has been shown that any posterior median of $\theta$ is a Bayes estimate of $\theta$.

## Part c

Here our goal will be to show that for any value of $a$, the derivative of $L(\theta, a)$ will evaluate to $0$ where $k_0$ and $k_1$ are nonnegative numbers.

\[
\begin{aligned}
\frac{d}{da}\big[E[L(a|y)]\big] & = \frac{d}{da}\bigg[{\int}_{-\infty}^a k_1(a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty k_0(\theta - a)p(\theta|y)d\theta\bigg] \\
& = {\int}_{-\infty}^a \frac{d}{da}k_1(a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty \frac{d}{da}k_0(\theta - a)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a {k_1}p(\theta|y)d\theta + {\int}_{a}^\infty(-k_0)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a {k_1}p(\theta|y)d\theta - {\int}_{a}^\infty {k_0}p(\theta|y)d\theta \\
& = k_1 {\int}_{-\infty}^a p(\theta|y)d\theta - k_0 {\int}_{a}^\infty p(\theta|y)d\theta \\
\end{aligned}
\]

Noting that: $k_0 \int_a^\infty p(\theta|y)d\theta = k_0 - k_0{\int_{-\infty}^a} p(\theta|y)d\theta$

\[
\begin{aligned}
k_1 {\int}_{-\infty}^a p(\theta|y)d\theta - k_0 {\int}_{a}^\infty p(\theta|y)d\theta & = k_1{\int_{-\infty}^a}p(\theta|y)d\theta - \bigg[k_0 - k_0{\int_{-\infty}^a} p(\theta|y)d\theta{\bigg]} \\
& = k_1{\int_{-\infty}^a}p(\theta|y)d\theta + k_0{\int_{-\infty}^a} p(\theta|y)d\theta - k_0 \\
& = (k_1 + k_0){\int_{-\infty}^a}p(\theta|y)d\theta - k_0 \\
\end{aligned}
\]

Now setting ${\int_{-\infty}^a}p(\theta|y)d\theta = \frac{k_0}{k_0 + k_1}$ we get our result that any quantile is a Bayes estimate of $\theta$.
\newline
\newline
Taking the second derivative we again get a positive number, thus again indicating that it is a minimizing statistic.

# Problem 2

n = 20
\newline
Sampling Distribution: $y|\theta \sim Binomial(n = 20, \theta)$
\newline
Prior Distribution: $\theta \sim Beta(\alpha = 2, \beta = 20)$
\newline
Posterior Distribution:
\newline
\[
\begin{aligned}
p(\theta|y) & = \binom{n}{y}\theta^y(1 - \theta)^{n - y} \times \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha - 1}(1 - \theta)^{\beta - 1} \\
& = \binom{n}{y}\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{y + \alpha - 1}(1 - \theta)^{n - y + \beta - 1} \\
& \propto Beta(y + \alpha, (n - y) + \beta) \\
& = Beta(y + 2, (20 - y) + 20)
\end{aligned}
\]

```{r, echo = FALSE}

### Load in the necessary packages

library(ggplot2)
library(coda)



##### Problem 2 #####



## Set the parameter values

y <- 0
n <- 20
alpha <- 2
beta <- 20

## Set the theta values

theta <- seq(from = 0, to = 1, length.out = 1000)

```

## Part i

$y = 0$
\newline

```{r, echo = FALSE, fig.height = 3}

### Part i ###



## Plot the posterior distribution

post_beta_dens <- dbeta(x = theta, shape1 = y + alpha, shape2 = (n - y) + beta)

ggplot() +
    geom_line(aes(x = theta, y = post_beta_dens), col = "blue") +
    geom_line(aes(x = theta, y = dbeta(x = theta, shape1 = alpha, shape2 = beta)), col = "green") +
    geom_vline(aes(xintercept = (y / n)), col = "red") +
    labs(x = "Theta", y = "Density", title = "Beta Density",
         subtitle = "Blue - Posterior Distribution   /   Green - Prior Distribution   /   Red - MLE")

```

## Part ii

```{r, echo = FALSE}

### Part ii ###



## Draw a sample from my posterior distribution

post_beta_rand <- rbeta(n = 10000, shape1 = y + alpha, shape2 = (n - y) + beta)

## Compute the HPD interval

bayes_int <- as.vector(HPDinterval(as.mcmc(post_beta_rand), prob = 0.95)[1, 1:2])

## Calculate the MLE

y_hat <- (y / n)

## Compute the frequentist interval

freq_int <- c((y_hat) - (1.96 * (sqrt(y_hat * (1 - y_hat)) / 2)),
              (y_hat) + (1.96 * (sqrt(y_hat * (1 - y_hat)) / 2)))

## Output the results

cat("HPD Interval: ", "(", bayes_int[1], ",", bayes_int[2], ")")
cat("Frequentist Interval: ", "(", freq_int[1], ",", freq_int[2], ")")

```

## Part iii

```{r, echo = FALSE}

### Part iii ###



## Compute the log odds of our posterior beta distrbution

odds_samp <- log(post_beta_rand / (1 - post_beta_rand))

## Compute the HPS interval

bayes_int_odds <- as.vector(HPDinterval(as.mcmc(odds_samp), prob = 0.95)[1, 1:2])

## Output the result

cat("HPD Interval: ", "(", bayes_int_odds[1], ",", bayes_int_odds[2], ")")

```

# Problem 3

## Part i

My methodology for selecting my $\alpha$ and $\beta$ for my $\theta_1, \theta_2 \sim Gamma(\alpha, \beta)$ distribution is as follows. First, I estimated my $\lambda$ parameter from my Poisson distribution by $\Sigma_{i=1}^n \frac{y_i}{n}$. Then, I generated a sample of 1000 data points from a Poisson distribution with my esimated $\lambda$ parameter. I calculated the mean and variance of this sample, and using these values, ascertained the values of $\alpha$ and $\beta$ of a Gamma distribution by using the formula for mean ($\frac{\alpha}{\beta}$) and variance ($\frac{\alpha}{\beta^2}$).

```{r, echo = FALSE}

## Get the poisson parameter

lambda <- (217 + 66) / 155

## Generate poisson data with the parameter

pois_data <- rpois(1000, lambda = lambda)

## Sample mean and variance

samp_mean <- mean(pois_data)
samp_var <- var(pois_data)

## Compute the gamma parameters

find_gamma_params <- function(mu, sigma_sq) {
    
    beta <- mu / sigma_sq
    alpha <- beta * mu
    return(c(alpha, beta))
    
}

gamma_params <- find_gamma_params(samp_mean, samp_var)

cat("Gamma Parameters")
cat("Alpha Parameter: ", round(gamma_params[1], 4))
cat("Beta Parameter: ", round(gamma_params[2], 4))

```

## Part ii

Posterior Distributions:
\newline
\[
\begin{aligned}
p(\theta|y_1) & \propto p(y_1| \theta)p(\theta) \\
& = \frac{\theta^{y_1}e^{-\theta}}{y_1!}\frac{\beta^{\alpha}}{\Gamma(\alpha)}\theta^{\alpha - 1}e^{-{\beta}\theta} \\
& \propto {\theta^{y_1}}{e^{-\theta}}\theta^{\alpha - 1}e^{{-\beta}\theta} \\
& = \theta^{y_1 + \alpha - 1}e^{-(1 + \beta)\theta} \\
& \sim Gamma(y_1 + \alpha, \beta + 1)
\end{aligned}
\]
\newline
\[
\begin{aligned}
p(\theta|y_2) & \propto p(y_2| \theta)p(\theta) \\
& = \frac{\theta^{y_2}e^{-\theta}}{y_2!}\frac{\beta^{\alpha}}{\Gamma(\alpha)}\theta^{\alpha - 1}e^{-{\beta}\theta} \\
& \propto {\theta^{y_2}}{e^{-\theta}}\theta^{\alpha - 1}e^{{-\beta}\theta} \\
& = \theta^{y_2 + \alpha - 1}e^{-(1 + \beta)\theta} \\
& \sim Gamma(y_2 + \alpha, \beta + 1)
\end{aligned}
\]

```{r, echo = FALSE, fig.height = 3}

### Part ii ###



## Set theta values

theta <- seq(from = 1, to = 150, by = 1)

## Set the sample values

y_1 <- 217
y_2 <- 66
n_1 <- 111
n_2 <- 44
lambda_1 <- 217 / 111
lambda_2 <- 66 / 44

## Generate samples from the posterior distributions

post_dens_y1 <- dgamma(x = theta, shape = y_1 + gamma_params[1], rate = gamma_params[2] + 1)
post_dens_y2 <- dgamma(x = theta, shape = y_2 + gamma_params[1], rate = gamma_params[2] + 1)
prior_dens <- dgamma(x = theta, shape = gamma_params[1], rate = gamma_params[2])

## Generate the plot

ggplot() +
    geom_line(aes(x = theta, y = post_dens_y1), col = "blue") +
    geom_line(aes(x = theta, y = post_dens_y2), col = "green") +
    geom_line(aes(x = theta, y = prior_dens), col = "orange") +
    geom_vline(aes(xintercept = lambda_1), col = "red") +
    geom_vline(aes(xintercept = lambda_2), col = "purple") +
    labs(x = "Theta", y = "Density", title = "Gamma Density",
         subtitle = "Blue - y1 Posterior   /   Green - y2 Posterior   /   Red - y1 MLE   /   Purple - y2 MLE")

```









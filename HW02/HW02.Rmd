---
title: 'Assignment #2'
author: "Elliot Smith"
date: "8/30/2018"
output: pdf_document
---

# Problem 1

## Part a

Here our goal will be to minimize $a$ to show that $a = E[\theta|y]$ is the unique Bayes estimate of $\theta$:

\[
\begin{aligned}
\frac{d}{da}E[L(a|y)] & = \frac{d}{da}{\int}L(\theta, a)p(\theta|y)d\theta \\
& = \frac{d}{da}{\int}(\theta - a)^2p(\theta|y)d\theta \\
& = -2{\int}(\theta - a)p(\theta|y)d\theta \\
& = -2\bigg[{\int}{\theta}p(\theta|y)d\theta - a{\int}p(\theta|y)d\theta\bigg] \\
& = -2\big[E[\theta|y] - a\big] \\
\end{aligned}
\]

$-2\big[E[\theta|y] - a\big] = 0$ when $a = E[\theta|y]$
\newline
\newline
To prove that it is a unique minimizing statistic, we must look at the second derivative:
\newline
\newline
$\frac{d}{da}(-2\big[E[\theta|y] - a\big]) = 2$
\newline
\newline
As $2 > 0$, this shows that it is a unique minimzing statistic.

## Part b

Here our goal will be to show that for any median value of $a$, the derivative of $L(\theta, a)$ will evaluate to $0$.

\[
\begin{aligned}
\frac{d}{da}\big[E[L(a|y)]\big] & = \frac{d}{da}\bigg[{\int}_{-\infty}^a (a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty (\theta - a)p(\theta|y)d\theta\bigg] \\
& = {\int}_{-\infty}^a \frac{d}{da}(a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty \frac{d}{da}(\theta - a)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a p(\theta|y)d\theta + {\int}_{a}^\infty(-1)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a p(\theta|y)d\theta - {\int}_{a}^\infty p(\theta|y)d\theta \\
& = \frac{1}{2} - \frac{1}{2} \\
& = 0
\end{aligned}
\]

As a result, it has been shown that any posterior median of $\theta$ is a Bayes estimate of $\theta$.

## Part c

Here our goal will be to show that for any value of $a$, the derivative of $L(\theta, a)$ will evaluate to $0$ where $k_0$ and $k_1$ are nonnegative numbers.

\[
\begin{aligned}
\frac{d}{da}\big[E[L(a|y)]\big] & = \frac{d}{da}\bigg[{\int}_{-\infty}^a k_1(a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty k_0(\theta - a)p(\theta|y)d\theta\bigg] \\
& = {\int}_{-\infty}^a \frac{d}{da}k_1(a - \theta)p(\theta|y)d\theta + {\int}_{a}^\infty \frac{d}{da}k_0(\theta - a)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a {k_1}p(\theta|y)d\theta + {\int}_{a}^\infty(-k_0)p(\theta|y)d\theta \\
& = {\int}_{-\infty}^a {k_1}p(\theta|y)d\theta - {\int}_{a}^\infty {k_0}p(\theta|y)d\theta \\
& = k_1 {\int}_{-\infty}^a p(\theta|y)d\theta - k_0 {\int}_{a}^\infty p(\theta|y)d\theta \\
\end{aligned}
\]

Noting that: $k_0 \int_a^\infty p(\theta|y)d\theta = k_0 - k_0{\int_{-\infty}^a} p(\theta|y)d\theta$

\[
\begin{aligned}
k_1 {\int}_{-\infty}^a p(\theta|y)d\theta - k_0 {\int}_{a}^\infty p(\theta|y)d\theta & = k_1{\int_{-\infty}^a}p(\theta|y)d\theta - \bigg[k_0 - k_0{\int_{-\infty}^a} p(\theta|y)d\theta{\bigg]} \\
& = k_1{\int_{-\infty}^a}p(\theta|y)d\theta + k_0{\int_{-\infty}^a} p(\theta|y)d\theta - k_0 \\
& = (k_1 + k_0){\int_{-\infty}^a}p(\theta|y)d\theta - k_0 \\
\end{aligned}
\]

Now setting ${\int_{-\infty}^a}p(\theta|y)d\theta = \frac{k_0}{k_0 + k_1}$ we get our result that any quantile is a Bayes estimate of $\theta$.
\newline
\newline
Taking the second derivative we again get a positive number, thus again indicating that it is a minimizing statistic.













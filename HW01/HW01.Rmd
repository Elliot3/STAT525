---
title: 'Assignment #1'
author: "Elliot Smith"
date: "8/26/2018"
output: pdf_document
---

```{r, echo = FALSE}

## Suppress all warnings

options(warn=-1)

```

# Problem 1

## Part i

$f(x)$ is the pdf of any of the $x_i$, and since they are $iid$, they all follow one pdf.

The joint pdf is: $f_{X_1, ..., X_n}(x_1, ..., x_n) = f(x_1) \times ... \times f(x_n)$ because they are $iid$.

Since you can multiply the right-hand side in any order, this implies symmetry in regards to the left-hand side.

As a result, $X_1, ..., X_n$ are exchangeable.

## Part ii

\[
\begin{aligned}
p(y_1, ..., y_n) & = \int p(y_1, ..., y_n|\theta)p(\theta)d(\theta) \\
& = \int \left(\prod_{i=1}^{n} p(y_i|\theta)\right)p(\theta)d(\theta)) \\
& = \int \left(\prod_{i=1}^{n} p(y_{\pi_i}|\theta)\right)p(\theta)d(\theta)) \\
& = \int p(y_{\pi_1, ..., y_{\pi_n}}|\theta)p(\theta)d(\theta) \\
& = p(y_{\pi_1, ..., y_{\pi_n}})
\end{aligned}
\]

Where:

* The first line is the definition of marginal probability
* The second line is because the $Y_i$'s are conditionally $iid$
* The third line is because the product does not depend on order
* The fourth line we are converting back to the form used in the first line
* Finally, the last line is the definition of marginal probability

# Problem 2

## Part a

Prior Density: $p(\theta) = 1$
\newline
Sampling Distribution: $p(y|\theta) = \binom{n}{y}\theta^y(1 - \theta)^{n - y}$
\newline
\newline
Posterior Density: $p(\theta|y) \propto p(y|\theta)p(\theta) = \binom{n}{y}\theta^y(1 - \theta)^{n - y}$
\newline
Posterior Distribution: $\theta|y \sim Beta(y + 1, (n - y) + 1)$
\newline

\[
\begin{aligned}
\binom{n}{y}\frac{\Gamma(y + 1)\Gamma(n - y + 1)}{\Gamma((y + 1) + (n - y + 1))} & = \binom{n}{y}\frac{\Gamma(y + 1)\Gamma(n - y + 1)}{\Gamma(n + 2)} \\
& = \frac{n!}{y!(n - y)!}\frac{y!(n - y)!}{(n + 1)!} \\
& = \frac{n!}{(n + 1)!} \\
& = \frac{1}{n + 1}
\end{aligned}
\]

## Part b

Prior Distribution: $\theta \sim Beta(\alpha, \beta)$
\newline
Sampling Distribution: $y|\theta \sim Binomial(n, \theta)$
\newline
\newline
Posterior Density:
\newline
\[
\begin{aligned}
p(\theta|y) & = \binom{n}{y}\theta^y(1 - \theta)^{n - y} \times \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha - 1}(1 - \theta)^{\beta - 1} \\
& = \binom{n}{y}\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{y + \alpha - 1}(1 - \theta)^{n - y + \beta - 1} \\
& \propto Beta(y + \alpha, (n - y) + \beta)
\end{aligned}
\]
\newline
Posterior Mean:
\newline
\[
\begin{aligned}
\frac{y + \alpha}{\alpha + \beta + n} & = \frac{y}{n} + \lambda\left(\frac{\alpha}{\alpha + \beta} - \frac{y}{n}\right) \\
\frac{y + \alpha}{\alpha + \beta + n} - \frac{y}{n} & = \lambda\left(\frac{\alpha}{\alpha + \beta} - \frac{y}{n}\right) \\
\frac{ny + n\alpha - \alpha{y} - \beta{y} - ny}{(\alpha + \beta + n)n} & = \lambda\left(\frac{n\alpha - \alpha{y} - \beta{y}}{(\alpha + \beta)n}\right) \\
\lambda & = \frac{\alpha + \beta}{\alpha + \beta + n}
\end{aligned}
\]
\newline
Since $\lambda$ will always be between $0$ and $1$ the Posterior Mean will act as a weighted average between our Prior Mean, $\frac{y}{n}$, and the data.

## Part c

Posterior Distribution: $\theta|y \sim Beta (y + \alpha, (n - y) + \beta)$
\newline
Prior Variance ($\alpha = 1, \beta = 1$): $\frac{1}{12}$
\newline
Posterior Variance ($\alpha = 1, \beta = 1$):
\newline
\newline
\[
\begin{aligned}
\frac{(y + 1)(n - y + 1)}{(n + 2)^2{(n + 3)}} & = \frac{ny - y^2 + y + n - y + 1}{(n^2 + 4n + 4)(n + 3)} \\
& = \frac{ny - y^2 + y + n - y + 1}{n^3 + 3n^2 + 4n^2 + 12n + 4n + 12} \\
& = \frac{-y^2 +ny + n + 1}{n^3 + 7n^2 + 16n + 12}
\end{aligned}
\]
\newline
Now, we can deduce that smaller values of n will maximize this quantity; since $n \geq y$, we will set $n = y = 1$.
\newline
\newline
Posterior Variance ($n = y = 1$): $\frac{-y^2 +ny + n + 1}{n^3 + 7n^2 + 16n + 12} = \frac{2}{36} = \frac{1}{18}$
\newline
\newline
Thus, the Posterior Variance, which we just maximized, is always less than the Prior Variance of $\frac{1}{12}$.

## Part d

* $n = y = 1$
* $\alpha = 1$
* $\beta = 10$

Prior Distribution: $\theta \sim Beta(\alpha, \beta)$
\newline
Posterior Distribution: $\theta|y \sim Beta (y + \alpha, (n - y) + \beta)$
\newline
\newline
Prior Variance: $\frac{(1)(10)}{(11)^{2}(12)} = \frac{10}{1452} = 0.0069$
\newline
Posterior Variance: $\frac{(2)(10)}{(12)^{2}(13)} = \frac{20}{1872} = 0.0107$

# Problem 3

## Part a

Prior Distribution: $\theta \sim Beta (\alpha, \beta)$
\newline
Prior Mean: $0.6$
\newline
Prior Variance: $0.09$
\newline
\newline
Sampling Distribution: $y|\theta \sim Binomial(n, \theta)$
\newline
\[
\begin{aligned}
\mu & = \frac{\alpha}{\alpha + \beta} \\
(\alpha + \beta)\mu & = \alpha \\
\alpha{\mu} + \beta{\mu} & = \alpha \\
\beta{\mu} & = \alpha - \alpha{\mu} \\
\beta & = \alpha(\frac{1}{\mu} - 1)
\end{aligned}
\]
\newline
\newline
\[
\begin{aligned}
\sigma^2 & = \frac{\alpha{\beta}}{(\alpha + \beta)^2{(\alpha + \beta + 1)}} \\
\alpha & = \left(\frac{1 - \mu}{\sigma^2} - \frac{1}{\mu}\right)\mu^2
\end{aligned}
\]
\newline
\newline
$\alpha = 1$
\newline
$\beta = 0.67$

```{r, echo = FALSE, fig.height = 3}

## Load in necessary packages

library(ggplot2)

## Set mean and variance

mu <- 0.6
var <- 0.09

## Estimate the beta parameters

est_beta_params <- function(mu, var) {
    
    alpha <- (((1 - mu) / var) - (1 / mu)) * mu^2
    beta <- alpha * ((1 / mu) - 1)
    return(round(c(alpha, beta), 2))
    
}

beta_params <- est_beta_params(mu, var)

## Establish the x-axis values

theta <- seq(0, 1, length.out = 100)

## Set the beta density

beta_density <- dbeta(x = theta,
                      shape1 = beta_params[1],
                      shape2 = beta_params[2])

beta_density <- beta_density[-length(beta_density)]
theta <- theta[-length(theta)]

## Build the density plot

ggplot() +
    geom_line(aes(x = theta, y = beta_density)) +
    labs(x = "Theta", y = "Density", title = "Beta Density")

```

## Part b

$n = 1000$
\newline
$y = 650$
\newline
Prior Distribution: $\theta \sim Beta(\alpha, \beta)$
\newline
Sampling Distribution: $y|\theta \sim Binomial(n, \theta)$
\newline
\newline
Posterior Density:
\newline
\[
\begin{aligned}
p(\theta|y) & = \binom{n}{y}\theta^y(1 - \theta)^{n - y} \times \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha - 1}(1 - \theta)^{\beta - 1} \\
& = \binom{n}{y}\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{y + \alpha - 1}(1 - \theta)^{n - y + \beta - 1} \\
& \propto Beta(y + \alpha, (n - y) + \beta)
\end{aligned}
\]
\newline
$\alpha_{post} = y + \alpha$
\newline
$\beta_{post} = (n - y) + \beta$
\newline
Posterior Mean: $\mu_{post} = \frac{y + \alpha}{(y + \alpha) + ((n - y) + \beta)} = 0.6499$
\newline
Posterior Variance: $\sigma^2_{post} = \frac{(y + \alpha)((n - y) + \beta)}{((y + \alpha) + ((n - y) + \beta))^2((y + \alpha) + ((n - y) + \beta) + 1)} = 0.0151$

```{r, echo = FALSE, fig.height = 3}

## Set the sample size

n <- 1000

## Set the number of yes votes

y <- n * 0.65

## Set post alpha and beta

post_alpha <- y + beta_params[1]
post_beta <- (n - y) + beta_params[2]

## Posterior mean and variance

post_mean <- round(post_alpha / (post_alpha + post_beta), 4)
post_var <- round(sqrt((post_alpha * post_beta) / ((post_alpha + post_beta)^2 * (post_alpha + post_beta + 1))), 4)

## Calculate the posterior density

post_density <- dbeta(x = theta,
                      shape1 = post_alpha,
                      shape2 = post_beta)

## Build the density plot

ggplot() +
    geom_line(aes(x = theta, y = post_density)) +
    labs(x = "Theta", y = "Density", title = "Beta Density") +
    xlim(c(0.5, 0.75))

```

## Part c

### First Sensitivity Check - Uniform Prior

Prior Mean: $\frac{1}{2}$
\newline
Prior Variance: $\frac{1}{12}$
\newline
Prior Distribution: $\theta \sim Uniform(0, 1)$
\newline
Sampling Distribution: $y|\theta \sim Binomial(n, \theta)$
\newline
Posterior Density:
\newline
\[
\begin{aligned}
p(\theta|y) & = \binom{n}{y}\theta^y(1 - \theta)^{n - y} \times 1 \\
& = \binom{n}{y}\theta^y(1 - \theta)^{n - y} \times 1 \\
& \propto Beta(y + 1, (n - y) + 1)
\end{aligned}
\]

```{r, echo = FALSE, fig.height = 3}

## First sensitivity check



## Set mean and variance

mu <- 0.5
var <- (1/12)

## Set post alpha and beta

post_alpha <- y + 1
post_beta <- (n - y) + 1

## Establish the x-axis values

theta <- seq(0, 1, length.out = 100)

## Set the beta density

beta_density <- dbeta(x = theta,
                      shape1 = post_alpha,
                      shape2 = post_beta)

beta_density <- beta_density[-length(beta_density)]
theta <- theta[-length(theta)]

## Build the density plot

ggplot() +
    geom_line(aes(x = theta, y = beta_density)) +
    labs(x = "Theta", y = "Density", title = "Beta Density") +
    xlim(c(0.5, 0.75))

```

### Second Sensitivity Check - Beta Prior

Prior Mean: $0.3$
\newline
Prior Variance: $0.001$
\newline
Prior Distribution: $\theta \sim Beta(62.7, 146.3)$
\newline
Sampling Distribution: $y|\theta \sim Binomial(n, \theta)$
\newline
\newline
Posterior Density:
\newline
\[
\begin{aligned}
p(\theta|y) & = \binom{n}{y}\theta^y(1 - \theta)^{n - y} \times \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha - 1}(1 - \theta)^{\beta - 1} \\
& = \binom{n}{y}\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{y + \alpha - 1}(1 - \theta)^{n - y + \beta - 1} \\
& \propto Beta(y + \alpha, (n - y) + \beta)
\end{aligned}
\]

```{r, echo = FALSE, fig.height = 3}

## Second sensitivity check



## Set mean and variance

mu <- 0.3
var <- 0.001

## Estimate the beta parameters

beta_params <- est_beta_params(mu, var)

## Set post alpha and beta

post_alpha <- y + beta_params[1]
post_beta <- (n - y) + beta_params[2]

## Establish the x-axis values

theta <- seq(0, 1, length.out = 100)

## Set the beta density

beta_density <- dbeta(x = theta,
                      shape1 = post_alpha,
                      shape2 = post_beta)

beta_density <- beta_density[-length(beta_density)]
theta <- theta[-length(theta)]

## Build the density plot

ggplot() +
    geom_line(aes(x = theta, y = beta_density)) +
    labs(x = "Theta", y = "Density", title = "Beta Density") +
    xlim(c(0.5, 0.75))

```

### Third Sensitivity Check - Beta Prior

Prior Mean: $0.9$
\newline
Prior Variance: $0.0005$
\newline
Prior Distribution: $\theta \sim Beta(161.1, 17.9)$
\newline
Sampling Distribution: $y|\theta \sim Binomial(n, \theta)$
\newline
\newline
Posterior Density:
\newline
\[
\begin{aligned}
p(\theta|y) & = \binom{n}{y}\theta^y(1 - \theta)^{n - y} \times \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha - 1}(1 - \theta)^{\beta - 1} \\
& = \binom{n}{y}\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{y + \alpha - 1}(1 - \theta)^{n - y + \beta - 1} \\
& \propto Beta(y + \alpha, (n - y) + \beta)
\end{aligned}
\]

```{r, echo = FALSE, fig.height = 3}

## Third sensitivity check



## Set mean and variance

mu <- 0.9
var <- 0.0005

## Estimate the beta parameters

beta_params <- est_beta_params(mu, var)

## Set post alpha and beta

post_alpha <- y + beta_params[1]
post_beta <- (n - y) + beta_params[2]

## Establish the x-axis values

theta <- seq(0, 1, length.out = 100)

## Set the beta density

beta_density <- dbeta(x = theta,
                      shape1 = post_alpha,
                      shape2 = post_beta)

beta_density <- beta_density[-length(beta_density)]
theta <- theta[-length(theta)]

## Build the density plot

ggplot() +
    geom_line(aes(x = theta, y = beta_density)) +
    labs(x = "Theta", y = "Density", title = "Beta Density") +
    xlim(c(0.5, 0.75))

```

### Conclusion

We can see that a prior distribution such as $Uniform(0, 1)$ has a negligible affect on the posterior distribution, whereas, our $Beta(\alpha, \beta)$ distributions with prior means and variances that are substantially different enough from the observed data will have a noticeable affect on the posterior distribution. This shows us how our prior distribution may have a large affect on our posterior distribution, depending on the family, and parameters of said family, that we select.



